<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark | Master Reference</title>
    <meta name="description" content="The official Reference.">
    
    
    <link rel="preload" href="/assets/css/0.styles.5852889d.css" as="style"><link rel="preload" href="/assets/js/app.ba1a83e9.js" as="script"><link rel="preload" href="/assets/js/16.0cf70ede.js" as="script"><link rel="prefetch" href="/assets/js/10.14c7f3cb.js"><link rel="prefetch" href="/assets/js/11.ad6ac139.js"><link rel="prefetch" href="/assets/js/12.360779c2.js"><link rel="prefetch" href="/assets/js/13.30c743a5.js"><link rel="prefetch" href="/assets/js/14.d78fc926.js"><link rel="prefetch" href="/assets/js/15.d42dfc75.js"><link rel="prefetch" href="/assets/js/17.22130cab.js"><link rel="prefetch" href="/assets/js/18.9b164e69.js"><link rel="prefetch" href="/assets/js/19.7ffe9761.js"><link rel="prefetch" href="/assets/js/2.ea9f70a5.js"><link rel="prefetch" href="/assets/js/20.aa1f8ad3.js"><link rel="prefetch" href="/assets/js/21.4164906d.js"><link rel="prefetch" href="/assets/js/22.51fd0277.js"><link rel="prefetch" href="/assets/js/23.6598fc20.js"><link rel="prefetch" href="/assets/js/24.28bcb24b.js"><link rel="prefetch" href="/assets/js/25.86c40695.js"><link rel="prefetch" href="/assets/js/26.ef245398.js"><link rel="prefetch" href="/assets/js/27.1910da2e.js"><link rel="prefetch" href="/assets/js/28.c1d4469a.js"><link rel="prefetch" href="/assets/js/29.2189a150.js"><link rel="prefetch" href="/assets/js/3.65e888c7.js"><link rel="prefetch" href="/assets/js/30.26e3117d.js"><link rel="prefetch" href="/assets/js/31.62cca8a2.js"><link rel="prefetch" href="/assets/js/32.ff6e624b.js"><link rel="prefetch" href="/assets/js/33.dc70f43d.js"><link rel="prefetch" href="/assets/js/34.6baa0970.js"><link rel="prefetch" href="/assets/js/35.4a514ab6.js"><link rel="prefetch" href="/assets/js/4.1af9f5be.js"><link rel="prefetch" href="/assets/js/5.2555e81e.js"><link rel="prefetch" href="/assets/js/6.08559af5.js"><link rel="prefetch" href="/assets/js/7.2b240d20.js"><link rel="prefetch" href="/assets/js/8.ffc53e6d.js"><link rel="prefetch" href="/assets/js/9.bff67984.js">
    <link rel="stylesheet" href="/assets/css/0.styles.5852889d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Master Reference</span></a> <div class="links" style="max-width:nullpx;"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/docs/cloud/linux.html" class="nav-link">Linux</a></div><div class="nav-item"><a href="/docs/programming/python.html" class="nav-link">Python</a></div><div class="nav-item"><a href="/docs/database/spark.html" class="nav-link router-link-exact-active router-link-active">Spark</a></div> <a href="https://github.com/flarco/ref-docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/docs/cloud/linux.html" class="nav-link">Linux</a></div><div class="nav-item"><a href="/docs/programming/python.html" class="nav-link">Python</a></div><div class="nav-item"><a href="/docs/database/spark.html" class="nav-link router-link-exact-active router-link-active">Spark</a></div> <a href="https://github.com/flarco/ref-docs" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><a href="/" class="sidebar-link">ref-docs</a></li><li><div class="sidebar-group"><p class="sidebar-heading"><span>Cloud</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/docs/cloud/amazon.html" class="sidebar-link">Amazon Web Services</a></li><li><a href="/docs/cloud/docker.html" class="sidebar-link">Docker</a></li><li><a href="/docs/cloud/git.html" class="sidebar-link">GIT</a></li><li><a href="/docs/cloud/linux.html" class="sidebar-link">Linux</a></li><li><a href="/docs/cloud/nginx.html" class="sidebar-link">NGinx</a></li></ul></div></li><li><div class="sidebar-group"><p class="sidebar-heading open"><span>Database</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/docs/database/elasticsearch.html" class="sidebar-link">ElasticSearch</a></li><li><a href="/docs/database/influxdb.html" class="sidebar-link">InfluxDB</a></li><li><a href="/docs/database/mysql.html" class="sidebar-link">MySQL</a></li><li><a href="/docs/database/oracle.html" class="sidebar-link">Oracle</a></li><li><a href="/docs/database/postgres.html" class="sidebar-link">PostgeSQL</a></li><li><a href="/docs/database/sas.html" class="sidebar-link">SAS</a></li><li><a href="/docs/database/spark.html" class="active sidebar-link">Spark</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/database/spark.html#main-documentation" class="sidebar-link">Main Documentation</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#master-options" class="sidebar-link">Master Options</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#hive-connection" class="sidebar-link">Hive connection</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#spark-on-yarn" class="sidebar-link">Spark on YARN</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#partitioning" class="sidebar-link">Partitioning</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#python" class="sidebar-link">Python</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#spark-2-1-init-boilerplate" class="sidebar-link">Spark 2.1 Init Boilerplate</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#example-links" class="sidebar-link">Example Links</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#code-help" class="sidebar-link">Code Help</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#pivot" class="sidebar-link">Pivot</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#n-grams" class="sidebar-link">N-grams</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#histogram" class="sidebar-link">Histogram</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#fill-nulls-down" class="sidebar-link">Fill nulls down</a></li><li class="sidebar-sub-header"><a href="/docs/database/spark.html#packaging-and-submitting" class="sidebar-link">Packaging and Submitting</a></li></ul></li><li><a href="/docs/database/mongodb.html" class="sidebar-link">MongoDB</a></li></ul></div></li><li><div class="sidebar-group"><p class="sidebar-heading"><span>Programming</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/docs/programming/android.html" class="sidebar-link">Android</a></li><li><a href="/docs/programming/go.html" class="sidebar-link">GO</a></li><li><a href="/docs/programming/java.html" class="sidebar-link">Java</a></li><li><a href="/docs/programming/scala.html" class="sidebar-link">Scala</a></li><li><a href="/docs/programming/nodejs.html" class="sidebar-link">NodeJS</a></li><li><a href="/docs/programming/javascript.html" class="sidebar-link">JavaScript</a></li><li><a href="/docs/programming/powershell.html" class="sidebar-link">PowerShell</a></li><li><a href="/docs/programming/python-database.html" class="sidebar-link">Python | Database</a></li><li><a href="/docs/programming/python-jupyter.html" class="sidebar-link">Python | Jupyter</a></li><li><a href="/docs/programming/python-links.html" class="sidebar-link">Python Links</a></li><li><a href="/docs/programming/python.html" class="sidebar-link">Python</a></li><li><a href="/docs/programming/ruby.html" class="sidebar-link">Ruby</a></li></ul></div></li><li><div class="sidebar-group"><p class="sidebar-heading"><span>ETL</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/docs/etl/informatica.html" class="sidebar-link">Informatica</a></li><li><a href="/docs/etl/ssis.html" class="sidebar-link">SSIS</a></li><li><a href="/docs/etl/talend.html" class="sidebar-link">Talend</a></li></ul></div></li></ul> </div> <div class="page"> <div class="content"><h1 id="spark"><a href="#spark" aria-hidden="true" class="header-anchor">#</a> Spark</h1> <h2 id="main-documentation"><a href="#main-documentation" aria-hidden="true" class="header-anchor">#</a> Main Documentation</h2> <p><a href="https://spark.apache.org/docs/latest/index.html" target="_blank" rel="noopener noreferrer">https://spark.apache.org/docs/latest/index.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://docs.databricks.com/spark/latest/gentle-introduction/sparksession.html" target="_blank" rel="noopener noreferrer">https://docs.databricks.com/spark/latest/gentle-introduction/sparksession.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <strong><a href="https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details" target="_blank" rel="noopener noreferrer">https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></strong></p> <p>Configuration: <a href="https://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener noreferrer">https://spark.apache.org/docs/latest/configuration.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Spark Streaming: <a href="https://www.gitbook.com/book/jaceklaskowski/spark-structured-streaming/details" target="_blank" rel="noopener noreferrer">https://www.gitbook.com/book/jaceklaskowski/spark-structured-streaming/details<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
Kafka: <a href="https://www.gitbook.com/book/jaceklaskowski/apache-kafka/details" target="_blank" rel="noopener noreferrer">https://www.gitbook.com/book/jaceklaskowski/apache-kafka/details<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>JDBC: <a href="https://medium.com/@radek.strnad/tips-for-using-jdbc-in-apache-spark-sql-396ea7b2e3d3" target="_blank" rel="noopener noreferrer">https://medium.com/@radek.strnad/tips-for-using-jdbc-in-apache-spark-sql-396ea7b2e3d3<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Memory Management: <a href="https://0x0fff.com/spark-memory-management/" target="_blank" rel="noopener noreferrer">https://0x0fff.com/spark-memory-management/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Cheat Sheets:
<a href="https://www.qubole.com/resources/pyspark-cheatsheet/" target="_blank" rel="noopener noreferrer">https://www.qubole.com/resources/pyspark-cheatsheet/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf" target="_blank" rel="noopener noreferrer">https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Unit Testing: <a href="https://blog.cambridgespark.com/unit-testing-with-pyspark-fb31671b1ad8" target="_blank" rel="noopener noreferrer">https://blog.cambridgespark.com/unit-testing-with-pyspark-fb31671b1ad8<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="master-options"><a href="#master-options" aria-hidden="true" class="header-anchor">#</a> Master Options</h2> <table><thead><tr><th>Master URL</th> <th>Meaning</th></tr></thead> <tbody><tr><td>local</td> <td>Run Spark locally with one worker thread (i.e. no parallelism at all).</td></tr> <tr><td>local[K]</td> <td>Run Spark locally with K worker threads (ideally, set this to the number of cores on your machine).</td></tr> <tr><td>local[K,F]</td> <td>Run Spark locally with K worker threads and F maxFailures (see spark.task.maxFailures for an explanation of this variable)</td></tr> <tr><td>local[*]</td> <td>Run Spark locally with as many worker threads as logical cores on your machine.</td></tr> <tr><td>local[*,F]</td> <td>Run Spark locally with as many worker threads as logical cores on your machine and F maxFailures.</td></tr> <tr><td>spark://HOST:PORT</td> <td>Connect to the given Spark standalone cluster master. The port must be whichever one your master is configured to use, which is 7077 by default.</td></tr> <tr><td>spark://HOST1:PORT1,HOST2:PORT2</td> <td>Connect to the given Spark standalone cluster with standby masters with Zookeeper. The list must have all the master hosts in the high availability cluster set up with Zookeeper. The port must be whichever each master is configured to use, which is 7077 by default.</td></tr> <tr><td>mesos://HOST:PORT</td> <td>Connect to the given Mesos cluster. The port must be whichever one your is configured to use, which is 5050 by default. Or, for a Mesos cluster using ZooKeeper, use mesos://zk://.... To submit with --deploy-mode cluster, the HOST:PORT should be configured to connect to the MesosClusterDispatcher.</td></tr> <tr><td>yarn</td> <td>Connect to a YARN cluster in client or cluster mode depending on the value of --deploy-mode. The cluster location will be found based on the HADOOP_CONF_DIR or YARN_CONF_DIR variable.</td></tr></tbody></table> <h2 id="hive-connection"><a href="#hive-connection" aria-hidden="true" class="header-anchor">#</a> Hive connection</h2> <p>Need to set up the <code>hive-site.xml</code> file in the <code>conf/</code> folder.</p> <p><a href="https://community.cloudera.com/t5/Advanced-Analytics-Apache-Spark/how-to-access-the-hive-tables-from-spark-shell/td-p/36609" target="_blank" rel="noopener noreferrer">https://community.cloudera.com/t5/Advanced-Analytics-Apache-Spark/how-to-access-the-hive-tables-from-spark-shell/td-p/36609<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="http://www.cloudera.com/documentation/cdh/5-1-x/CDH5-Security-Guide/cdh5sg_hiveserver2_security.html#topic_9_1_unique_2" target="_blank" rel="noopener noreferrer">http://www.cloudera.com/documentation/cdh/5-1-x/CDH5-Security-Guide/cdh5sg_hiveserver2_security.html#topic_9_1_unique_2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>This will allow the use of master <code>local[10]</code> with a connection to Hive tables.</p> <h3 id="kerberos-authentication-to-hive-metastore"><a href="#kerberos-authentication-to-hive-metastore" aria-hidden="true" class="header-anchor">#</a> Kerberos Authentication to Hive Metastore</h3> <p>Still unsure how to do this. The keys <code>spark.yarn.keytab</code> and <code>spark.yarn.principal</code> are for accessing the YARN cluster, not the hive metastore.</p> <p>Could try this, right before Spark connection (<a href="https://www.ibm.com/support/knowledgecenter/en/SSPT3X_3.0.0/com.ibm.swg.im.infosphere.biginsights.admin.doc/doc/kerberos_hive.html" target="_blank" rel="noopener noreferrer">link<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>):</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>security</span><span class="token punctuation">.</span><span class="token class-name">UserGroupInformation</span> as <span class="token class-name">UserGroupInformation</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf</span><span class="token punctuation">.</span><span class="token class-name">Configuration</span>

cd <span class="token operator">=</span> <span class="token function">dict2</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_conn_dict<span class="token punctuation">)</span>
conf <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span><span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">&quot;hadoop.security.authentication&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;Kerberos&quot;</span><span class="token punctuation">)</span>
<span class="token class-name">UserGroupInformation</span><span class="token punctuation">.</span><span class="token function">setConfiguration</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
<span class="token class-name">UserGroupInformation</span><span class="token punctuation">.</span><span class="token function">loginUserFromKeytab</span><span class="token punctuation">(</span>cd<span class="token punctuation">.</span>user<span class="token punctuation">,</span> cd<span class="token punctuation">.</span>keytab<span class="token punctuation">)</span>
</code></pre></div><h2 id="spark-on-yarn"><a href="#spark-on-yarn" aria-hidden="true" class="header-anchor">#</a> Spark on YARN</h2> <p>Set the keys <code>spark.yarn.keytab</code> and <code>spark.yarn.principal</code> appropriately.</p> <h2 id="partitioning"><a href="#partitioning" aria-hidden="true" class="header-anchor">#</a> Partitioning</h2> <p><a href="https://blog.deepsense.ai/optimize-spark-with-distribute-by-and-cluster-by/" target="_blank" rel="noopener noreferrer">https://blog.deepsense.ai/optimize-spark-with-distribute-by-and-cluster-by/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="python"><a href="#python" aria-hidden="true" class="header-anchor">#</a> Python</h2> <h3 id="spark-1-6"><a href="#spark-1-6" aria-hidden="true" class="header-anchor">#</a> Spark 1.6</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> pyspark <span class="token keyword">import</span> SparkContext
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SQLContext
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> HiveContext
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> functions <span class="token keyword">as</span> F
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>window <span class="token keyword">import</span> Window


hiveC <span class="token operator">=</span> HiveContext<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>
sqlC <span class="token operator">=</span> SQLContext<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>
<span class="token comment"># sqlc = hiveC</span>

<span class="token comment"># read from text file</span>
rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/apps/hive/warehouse/schema.db/stg_dq5&quot;</span><span class="token punctuation">)</span>
rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># read from text file</span>
df <span class="token operator">=</span> sqlC<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">&quot;com.databricks.spark.csv&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;header&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;inferschema&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;mode&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;DROPMALFORMED&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;/file.csv&quot;</span><span class="token punctuation">)</span>


<span class="token comment"># read from SQL</span>

sql <span class="token operator">=</span> <span class="token triple-quoted-string string">''' select * FROM shema.stg_dq4 '''</span>
df <span class="token operator">=</span> hiveC<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>sql<span class="token punctuation">)</span> <span class="token comment"># loads into pipeline</span>
df<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">'stg_dq4'</span><span class="token punctuation">)</span>

sql <span class="token operator">=</span> <span class="token triple-quoted-string string">'''
with dq4 as (
  select
    *,
    lag(account_nbr, 1) over (order by account_nbr, account_seq_num) as prev_account_nbr,
    lag(date_time, 1) over (order by account_nbr, account_seq_num) as prev_date_time
  from schema.stg_dq4
)
select
  qcn,
  ucid,
  case
    when prev_account_nbr = account_nbr
      and unix_timestamp(date_time) - unix_timestamp(prev_date_time) &lt; 20*60
      then 'N'
    else 'Y'
  end as new_session_ind
from dq4
'''</span>
df3 <span class="token operator">=</span> hiveC<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>

sql <span class="token operator">=</span> <span class="token triple-quoted-string string">'''
select
  *,
  lag(account_nbr, 1) over (order by account_nbr, account_seq_num) as prev_account_nbr,
  lag(date_time, 1) over (order by account_nbr, account_seq_num) as prev_date_time
from stg_dq4
'''</span>



<span class="token comment"># add unique IDs</span>
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions <span class="token keyword">import</span> monotonically_increasing_id
df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span> monotonically_increasing_id<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># add unique IDs</span>
rdd2 <span class="token operator">=</span> df<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>zipWithUniqueId<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Exercise</span>
rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

df <span class="token operator">=</span> sqlc<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&quot;account_nbr&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;date_time&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

my_window <span class="token operator">=</span> Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span><span class="token string">&quot;account_nbr&quot;</span><span class="token punctuation">)</span>

df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;prv_date_time&quot;</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>lag<span class="token punctuation">(</span>df<span class="token punctuation">.</span>date_time<span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>my_window<span class="token punctuation">)</span><span class="token punctuation">)</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;prv_account_nbr&quot;</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>lag<span class="token punctuation">(</span>df<span class="token punctuation">.</span>account_nbr<span class="token punctuation">)</span><span class="token punctuation">.</span>over<span class="token punctuation">(</span>my_window<span class="token punctuation">)</span><span class="token punctuation">)</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;diff_sec&quot;</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>when<span class="token punctuation">(</span>F<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span>df<span class="token punctuation">.</span>date_time <span class="token operator">-</span> df<span class="token punctuation">.</span>prv_date_time<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                              <span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span>df<span class="token punctuation">.</span>date_time <span class="token operator">-</span> df<span class="token punctuation">.</span>prv_date_time<span class="token punctuation">)</span><span class="token punctuation">)</span>

df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


session_id <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">def</span> <span class="token function">customFunction</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> row<span class="token punctuation">.</span>account_nbr <span class="token operator">==</span> row<span class="token punctuation">.</span>prv_account_nbr<span class="token punctuation">:</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span>row<span class="token punctuation">.</span>date_time <span class="token operator">-</span> row<span class="token punctuation">.</span>prv_date_time<span class="token punctuation">)</span><span class="token punctuation">.</span>total_seconds<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">20</span><span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">:</span>
        session_id <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      session_id <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>row<span class="token punctuation">.</span>account_nbr<span class="token punctuation">,</span> row<span class="token punctuation">.</span>date_time<span class="token punctuation">,</span> session_id<span class="token punctuation">)</span>

sample2 <span class="token operator">=</span> df<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>customFunction<span class="token punctuation">)</span>
sample2<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>





<span class="token comment">####################################################################################</span>
<span class="token comment">### Spark 2.1</span>

<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>window <span class="token keyword">import</span> Window
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> <span class="token operator">*</span>

spark <span class="token operator">=</span> SparkSession<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>

<span class="token comment"># Configurations</span>
spark<span class="token punctuation">.</span>conf<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;spark.sql.shuffle.partitions&quot;</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>conf<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;spark.executor.memory&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;2g&quot;</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>setCurrentDatabase<span class="token punctuation">(</span><span class="token string">'lake_cl_ocds_team'</span><span class="token punctuation">)</span>

<span class="token comment"># Read from SQL</span>
df <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">''' select * FROM schema.stg_dq4 limit 10'''</span><span class="token punctuation">)</span>


<span class="token comment"># Read JSON</span>
df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;/home/webinar/person.json&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Rename DF Columns</span>
new_col1 <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token string">'.'</span> <span class="token keyword">in</span> c <span class="token keyword">else</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> df1<span class="token punctuation">.</span>columns<span class="token punctuation">]</span>
df1 <span class="token operator">=</span> df1<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token operator">*</span>new_col1<span class="token punctuation">)</span>
new_col2 <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token string">'.'</span> <span class="token keyword">in</span> c <span class="token keyword">else</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> df2<span class="token punctuation">.</span>columns<span class="token punctuation">]</span>
df2 <span class="token operator">=</span> df2<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token operator">*</span>new_col2<span class="token punctuation">)</span>


<span class="token comment">####################################################################################</span>
<span class="token comment"># Sample</span>
<span class="token keyword">from</span> pyspark <span class="token keyword">import</span> SparkContext
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>window <span class="token keyword">import</span> Window
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types <span class="token keyword">import</span> <span class="token operator">*</span>

sc <span class="token operator">=</span> SparkContext<span class="token punctuation">(</span>appName<span class="token operator">=</span><span class="token string">&quot;App1&quot;</span><span class="token punctuation">)</span>
spark <span class="token operator">=</span> SparkSession<span class="token punctuation">(</span>sc<span class="token punctuation">)</span>

<span class="token comment"># Configurations</span>
spark<span class="token punctuation">.</span>conf<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;spark.sql.shuffle.partitions&quot;</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>conf<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;spark.executor.memory&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;10g&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># spark.catalog.setCurrentDatabase('schema')</span>

df1 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/__/Temp/schema.stg_dq4.t1.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">,</span> inferSchema<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/__/Temp/schema.stg_dq4.t2.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">,</span> inferSchema<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>


<span class="token comment"># clean columns</span>
new_col1 <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token string">'.'</span> <span class="token keyword">in</span> c <span class="token keyword">else</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> df1<span class="token punctuation">.</span>columns<span class="token punctuation">]</span>
df1 <span class="token operator">=</span> df1<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token operator">*</span>new_col1<span class="token punctuation">)</span>
new_col2 <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token string">'.'</span> <span class="token keyword">in</span> c <span class="token keyword">else</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> df2<span class="token punctuation">.</span>columns<span class="token punctuation">]</span>
df2 <span class="token operator">=</span> df2<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token operator">*</span>new_col2<span class="token punctuation">)</span>


df1<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">&quot;t1&quot;</span><span class="token punctuation">)</span>
df2<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">&quot;t2&quot;</span><span class="token punctuation">)</span>

sql<span class="token operator">=</span><span class="token triple-quoted-string string">'''
select
  t1.id,
  t1.account_nbr,
  t1.date_time,
  t2.min_id as session_id
from t1
join t2
  on t1.id &lt;= t2.max_id
  and t1.id &gt;= t2.min_id
'''</span>

df3 <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>
df3<span class="token punctuation">.</span>write<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">'/__/Temp/schema.stg_dq4.t3.csv'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span>


<span class="token comment">####################################################</span>
<span class="token comment"># CSV</span>

<span class="token comment"># Read from CSV</span>
df1 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/__/Temp/schema.stg_dq4.t1.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">,</span> inferSchema<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/__/Temp/schema.stg_dq4.t2.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">,</span> inferSchema<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Write to CSV</span>
file_path <span class="token operator">=</span> <span class="token string">&quot;/__/temp/test.csv&quot;</span>
df2<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>write<span class="token punctuation">.</span>csv<span class="token punctuation">(</span>file_path <span class="token operator">+</span> <span class="token string">'_'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'overwrite'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>system<span class="token punctuation">(</span><span class="token string">'cat {file_path}_/*.csv &gt; {file_path} &amp;&amp; rm -rf {file_path}_'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>file_path<span class="token operator">=</span>file_path<span class="token punctuation">)</span><span class="token punctuation">)</span>



<span class="token comment">####################################################</span>
<span class="token comment"># JDBC</span>

<span class="token comment"># Read - Lazy</span>
df1 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read \
    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:oracle:thin:@//..........&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CD_W_EXTRACT_1&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;pass&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Write</span>
df1<span class="token punctuation">.</span>write \
    <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:oracle:thin:@//........&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CD_W_EXTRACT_1&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;pass&quot;</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Hive</span>

<span class="token comment"># Save / Create table</span>
<span class="token comment"># Parquet is the default format, which does not play nice with Decimal fields: [https://stackoverflow.com/questions/36822224/how-is-apache-parquet-format-better-than-the-other-formats](https://stackoverflow.com/questions/36822224/how-is-apache-parquet-format-better-than-the-other-formats)</span>
<span class="token comment"># best to convert those to double.</span>
df1<span class="token punctuation">.</span>write<span class="token punctuation">.</span>saveAsTable<span class="token punctuation">(</span><span class="token string">'schema_name.stg_test1'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'overwrite'</span><span class="token punctuation">)</span>
df1<span class="token punctuation">.</span>write<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">&quot;orc&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTable<span class="token punctuation">(</span><span class="token string">'schema_name.stg_test1'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'overwrite'</span><span class="token punctuation">)</span>

<span class="token comment"># to convert to type Double</span>
dec_cols <span class="token operator">=</span> <span class="token punctuation">[</span>c<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> df1<span class="token punctuation">.</span>dtypes <span class="token keyword">if</span> <span class="token string">'decimal'</span> <span class="token keyword">in</span> c<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> col <span class="token keyword">in</span> dec_cols<span class="token punctuation">:</span>
  df1 <span class="token operator">=</span> <span class="token punctuation">(</span>
    df1<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span>col <span class="token operator">+</span> <span class="token string">'_'</span><span class="token punctuation">,</span> df1<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span>DoubleType<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span>drop<span class="token punctuation">(</span>col<span class="token punctuation">)</span>
     <span class="token punctuation">.</span>withColumnRenamed<span class="token punctuation">(</span>col <span class="token operator">+</span> <span class="token string">'_'</span><span class="token punctuation">,</span> col<span class="token punctuation">)</span>
  <span class="token punctuation">)</span>

<span class="token comment">#</span>
</code></pre></div><h2 id="spark-2-1-init-boilerplate"><a href="#spark-2-1-init-boilerplate" aria-hidden="true" class="header-anchor">#</a> Spark 2.1 Init Boilerplate</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> sys<span class="token punctuation">,</span> os<span class="token punctuation">,</span> datetime<span class="token punctuation">,</span> csv<span class="token punctuation">,</span> time
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'/code/python/libraries'</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> collections <span class="token keyword">import</span> namedtuple

<span class="token keyword">from</span> helpers <span class="token keyword">import</span> <span class="token punctuation">(</span>
  load_profiles<span class="token punctuation">,</span>
  log<span class="token punctuation">,</span>
  get_exception_message<span class="token punctuation">,</span>
  DIR<span class="token punctuation">,</span>
  now<span class="token punctuation">,</span>
  read_csvD<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">from</span> database <span class="token keyword">import</span> <span class="token punctuation">(</span>
  OracleConn<span class="token punctuation">,</span>
  Beeline<span class="token punctuation">,</span>
  HiveConn<span class="token punctuation">,</span>
  SparkConn<span class="token punctuation">,</span>
  Spark<span class="token punctuation">,</span>
  Sqoop<span class="token punctuation">,</span>
  PostgreSQLConn<span class="token punctuation">,</span>
  get_conn
<span class="token punctuation">)</span>

dbs <span class="token operator">=</span> load_profiles<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'PROFILE_YAML'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'databases'</span><span class="token punctuation">]</span>


sparko <span class="token operator">=</span> Spark<span class="token punctuation">(</span><span class="token builtin">globals</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> restart<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">####################################</span>
<span class="token comment">## READING data</span>

<span class="token comment"># Read from DB</span>
df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>jdbc_read<span class="token punctuation">(</span>dbs<span class="token punctuation">[</span><span class="token string">'DBNAME'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'schema.INVITATIONS'</span><span class="token punctuation">)</span>
df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>jdbc_read<span class="token punctuation">(</span>dbs<span class="token punctuation">[</span><span class="token string">'DBNAME'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'(SELECT * from schema.INVITATIONS where rownum &lt;= 1000)'</span><span class="token punctuation">)</span>

<span class="token comment"># Read from Hive</span>
df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">'select * from schema.mart_invitations limit 100'</span><span class="token punctuation">)</span>

<span class="token comment"># Read from Local CSV</span>
file_path <span class="token operator">=</span> <span class="token string">&quot;/user/schema/share/A428__.txt&quot;</span>
df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>read_csv2<span class="token punctuation">(</span>
  file_path<span class="token punctuation">,</span>
  delimeter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>
  timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss.SSS'</span><span class="token punctuation">,</span>
  dateFormat<span class="token operator">=</span><span class="token string">'MM/dd/yy'</span><span class="token punctuation">,</span>
  date_cols<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'event_day'</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>read_csv2<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> delimeter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> timestampFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">,</span> dateFormat<span class="token operator">=</span><span class="token string">'yyyy-MM-dd'</span><span class="token punctuation">,</span> date_cols<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">####################################</span>
<span class="token comment">## Writing data</span>

<span class="token comment"># Write to DB</span>
sparko<span class="token punctuation">.</span>jdbc_write<span class="token punctuation">(</span>df1<span class="token punctuation">,</span> dbs<span class="token punctuation">[</span><span class="token string">'DBNAME'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'schema.INVITATIONS'</span><span class="token punctuation">,</span> partitions<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> order_by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'survey_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Write to Local CSV</span>
sparko<span class="token punctuation">.</span>write_csv2<span class="token punctuation">(</span>df1<span class="token punctuation">,</span> <span class="token string">&quot;/user/schema/tmp/schema.invitations.csv&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Write to Hive</span>
<span class="token comment"># Parquet is the default format, which does not play nice with Decimal fields</span>
<span class="token comment"># [https://stackoverflow.com/questions/36822224/how-is-apache-parquet-format-better-than-the-other-formats](https://stackoverflow.com/questions/36822224/how-is-apache-parquet-format-better-than-the-other-formats)</span>
<span class="token comment"># best to convert those to double.</span>

sparko<span class="token punctuation">.</span>hive_write<span class="token punctuation">(</span>df1<span class="token punctuation">,</span> <span class="token string">'schema_name.stg_test1'</span><span class="token punctuation">,</span> order_by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
sparko<span class="token punctuation">.</span>hive_write<span class="token punctuation">(</span>df1<span class="token punctuation">.</span>write<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">&quot;orc&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'schema_name.stg_test1'</span><span class="token punctuation">,</span> order_by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>



sqoop<span class="token punctuation">.</span>to_hive<span class="token punctuation">(</span>dbs<span class="token punctuation">[</span><span class="token string">'DBNAME'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'schema.CD_W_EXTRACT_2'</span><span class="token punctuation">,</span> <span class="token string">'schema.CD_W_EXTRACT_2'</span><span class="token punctuation">)</span>

import_list <span class="token operator">=</span> \
<span class="token triple-quoted-string string">'''SCHEM1.TABLE1
SCHEM1.TABLE2
'''</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
sqoop<span class="token punctuation">.</span>to_hive_all<span class="token punctuation">(</span>dbs<span class="token punctuation">[</span><span class="token string">'DBNAME'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> import_list<span class="token operator">=</span>import_list<span class="token punctuation">,</span> tgt_schema<span class="token operator">=</span><span class="token string">'schema'</span><span class="token punctuation">)</span>
</code></pre></div><h1 id="java"><a href="#java" aria-hidden="true" class="header-anchor">#</a> Java</h1> <h2 id="example-links"><a href="#example-links" aria-hidden="true" class="header-anchor">#</a> Example Links</h2> <p><a href="https://stackoverflow.com/questions/22298192/how-to-run-a-spark-java-program" target="_blank" rel="noopener noreferrer">https://stackoverflow.com/questions/22298192/how-to-run-a-spark-java-program<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/mahmoudparsian/data-algorithms-book/blob/master/misc/how-to-submit-spark-job-to-yarn-from-java-code.md" target="_blank" rel="noopener noreferrer">https://github.com/mahmoudparsian/data-algorithms-book/blob/master/misc/how-to-submit-spark-job-to-yarn-from-java-code.md<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://hortonworks.com/tutorial/setting-up-a-spark-development-environment-with-java/" target="_blank" rel="noopener noreferrer">https://hortonworks.com/tutorial/setting-up-a-spark-development-environment-with-java/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://www.cloudera.com/documentation/enterprise/5-5-x/topics/spark_develop_run.html" target="_blank" rel="noopener noreferrer">https://www.cloudera.com/documentation/enterprise/5-5-x/topics/spark_develop_run.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="kotlin"><a href="#kotlin" aria-hidden="true" class="header-anchor">#</a> Kotlin</h3> <p>This project works with Spark 1.6: <code>/Users/larco/Temp/spark0</code> <a href="http://tomstechnicalblog.blogspot.com/2016/11/using-kotlin-language-with-spark.html" target="_blank" rel="noopener noreferrer">http://tomstechnicalblog.blogspot.com/2016/11/using-kotlin-language-with-spark.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/thomasnield/kotlin-spark-test" target="_blank" rel="noopener noreferrer">https://github.com/thomasnield/kotlin-spark-test<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h4 id="issues-with-building-a-single-jar"><a href="#issues-with-building-a-single-jar" aria-hidden="true" class="header-anchor">#</a> Issues with building a single jar. ⭐️</h4> <p>I am able to build a single jar fine with this project: https://github.com/techdev-solutions/spark-kotlin-example</p> <p>When I try with Apache Spark, with the SAME structure as above project, running the JAR file fails. It always gives the error: <code>Error: Could not find or load main class de.techdev.example.SparkExampleKt</code></p> <p>My conclusion is that the <a href="https://mvnrepository.com/artifact/org.apache.spark/spark-core_2.11/1.6.1" target="_blank" rel="noopener noreferrer">apache.spark maven JAR file<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> is somehow not correctly structured. When I include it and try to generate a fat JAR, it fails. However, we can run fine from IJ-IDEA without a fat jar. Try with Kotlin project here: <a href="https://files.larco.us/spark5.zip" target="_blank" rel="noopener noreferrer">https://files.larco.us/spark5.zip<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>This works with Spark 1.6.</p> <p>Two hurdles:</p> <ul><li>Use 2.2 instead of 1.6</li> <li><s>Be able to compile / build an executable file. Or perhaps have all the classpath JARs into one folder? I tried, but got error <code>Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: kotlin/jvm/internal/Intrinsics</code></s></li></ul> <p>Solution is <a href="https://github.com/johnrengelman/shadow" target="_blank" rel="noopener noreferrer">Shadow<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h4 id="successful-build-gradle"><a href="#successful-build-gradle" aria-hidden="true" class="header-anchor">#</a> Successful build.gradle</h4> <div class="language-javascript extra-class"><pre class="language-javascript"><code>group <span class="token string">'de.techdev.example'</span>
version <span class="token string">'1.0'</span>

buildscript <span class="token punctuation">{</span>
    ext<span class="token punctuation">.</span>kotlin_version <span class="token operator">=</span> <span class="token string">'1.1.2-2'</span>

    repositories <span class="token punctuation">{</span>
        <span class="token function">jcenter</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    dependencies <span class="token punctuation">{</span>
        classpath <span class="token string">&quot;org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version&quot;</span>
        classpath <span class="token string">'com.github.jengelman.gradle.plugins:shadow:2.0.1'</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

apply plugin<span class="token punctuation">:</span> <span class="token string">'kotlin'</span>
apply plugin<span class="token punctuation">:</span> <span class="token string">'com.github.johnrengelman.shadow'</span>
apply plugin<span class="token punctuation">:</span> <span class="token string">'application'</span>

mainClassName <span class="token operator">=</span> <span class="token string">'de.techdev.example.SparkExampleKt'</span>

repositories <span class="token punctuation">{</span>
    <span class="token function">mavenCentral</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>

<span class="token comment">// This will propogate to shadow</span>
jar <span class="token punctuation">{</span>

  manifest <span class="token punctuation">{</span>
      attributes <span class="token string">'Implementation-Title'</span><span class="token punctuation">:</span> <span class="token string">'Foobar'</span><span class="token punctuation">,</span>
              <span class="token string">'Implementation-Version'</span><span class="token punctuation">:</span> version<span class="token punctuation">,</span>
              <span class="token string">'Built-By'</span><span class="token punctuation">:</span> System<span class="token punctuation">.</span><span class="token function">getProperty</span><span class="token punctuation">(</span><span class="token string">'user.name'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              <span class="token string">'Built-Date'</span><span class="token punctuation">:</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              <span class="token string">'Built-JDK'</span><span class="token punctuation">:</span> System<span class="token punctuation">.</span><span class="token function">getProperty</span><span class="token punctuation">(</span><span class="token string">'java.version'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              <span class="token string">'Main-Class'</span><span class="token punctuation">:</span> mainClassName
  <span class="token punctuation">}</span>

  <span class="token comment">// from files(sourceSets.main.output.classesDir)</span>

  <span class="token comment">// from {</span>
  <span class="token comment">//   configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }</span>
  <span class="token comment">// }</span>

<span class="token punctuation">}</span>

shadowJar <span class="token punctuation">{</span>
  baseName <span class="token operator">=</span> project<span class="token punctuation">.</span>name <span class="token operator">+</span> <span class="token string">'-shadow'</span>
  classifier <span class="token operator">=</span> <span class="token keyword">null</span>
  version <span class="token operator">=</span> <span class="token keyword">null</span>

  <span class="token function">mergeServiceFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token function">transform</span><span class="token punctuation">(</span><span class="token parameter">com<span class="token punctuation">.</span>github<span class="token punctuation">.</span>jengelman<span class="token punctuation">.</span>gradle<span class="token punctuation">.</span>plugins<span class="token punctuation">.</span>shadow<span class="token punctuation">.</span>transformers<span class="token punctuation">.</span>AppendingTransformer</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    resource <span class="token operator">=</span> <span class="token string">'reference.conf'</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment">// This one works in general</span>
task <span class="token function">fatJar</span><span class="token punctuation">(</span><span class="token parameter">type<span class="token punctuation">:</span> Jar</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    baseName <span class="token operator">=</span> project<span class="token punctuation">.</span>name <span class="token operator">+</span> <span class="token string">'-fat'</span>
    <span class="token keyword">from</span> <span class="token punctuation">{</span> configurations<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>collect <span class="token punctuation">{</span> it<span class="token punctuation">.</span><span class="token function">isDirectory</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">?</span> it <span class="token punctuation">:</span> <span class="token function">zipTree</span><span class="token punctuation">(</span>it<span class="token punctuation">)</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span>
    <span class="token keyword">with</span> jar
    manifest <span class="token punctuation">{</span>
        attributes <span class="token string">'Main-Class'</span><span class="token punctuation">:</span> <span class="token string">'de.techdev.example.SparkExampleKt'</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment">// build.dependsOn fatJar</span>
build<span class="token punctuation">.</span>dependsOn shadowJar

dependencies <span class="token punctuation">{</span>
    compile <span class="token string">&quot;org.jetbrains.kotlin:kotlin-stdlib-jre8:$kotlin_version&quot;</span>
    compile <span class="token string">'org.apache.spark:spark-core_2.10:1.6.1'</span>
<span class="token punctuation">}</span>
</code></pre></div><h2 id="code-help"><a href="#code-help" aria-hidden="true" class="header-anchor">#</a> Code Help</h2> <h3 id="map"><a href="#map" aria-hidden="true" class="header-anchor">#</a> Map</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">transform_1</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">:</span>
  rec <span class="token operator">=</span> row<span class="token punctuation">.</span>asDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
  query <span class="token operator">=</span> parse_qs<span class="token punctuation">(</span>row<span class="token punctuation">.</span>cs_uri_query<span class="token punctuation">)</span> <span class="token keyword">if</span> row<span class="token punctuation">.</span>cs_uri_query <span class="token keyword">else</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
  query <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[\r\n\t]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> query<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> query<span class="token punctuation">}</span>

  d_du_query <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

  <span class="token keyword">if</span> <span class="token string">'d_du'</span> <span class="token keyword">in</span> query<span class="token punctuation">:</span>
    <span class="token comment"># get Campaign from d_du</span>
    d_data <span class="token operator">=</span> urlparse<span class="token punctuation">(</span>query<span class="token punctuation">[</span><span class="token string">'d_du'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    domain <span class="token operator">=</span> d_data<span class="token punctuation">.</span>netloc
    d_du_url <span class="token operator">=</span> <span class="token string">'{}://{}{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>d_data<span class="token punctuation">.</span>scheme<span class="token punctuation">,</span> d_data<span class="token punctuation">.</span>netloc<span class="token punctuation">,</span> d_data<span class="token punctuation">.</span>path<span class="token punctuation">)</span>
    d_du_query <span class="token operator">=</span> parse_qs<span class="token punctuation">(</span>d_data<span class="token punctuation">.</span>query<span class="token punctuation">)</span>
    d_du_query <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[\r\n\t]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> d_du_query<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> d_du_query<span class="token punctuation">}</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    domain <span class="token operator">=</span> <span class="token boolean">None</span>
    d_du_url <span class="token operator">=</span> <span class="token boolean">None</span>

  cs_referrer_parse <span class="token operator">=</span> urlparse<span class="token punctuation">(</span>rec<span class="token punctuation">[</span><span class="token string">'cs_referrer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">if</span> rec<span class="token punctuation">[</span><span class="token string">'cs_referrer'</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">None</span>
  rec<span class="token punctuation">[</span><span class="token string">'cs_referrer_domain'</span><span class="token punctuation">]</span> <span class="token operator">=</span> cs_referrer_parse<span class="token punctuation">.</span>netloc <span class="token keyword">if</span> cs_referrer_parse <span class="token keyword">else</span> <span class="token boolean">None</span>
  rec<span class="token punctuation">[</span><span class="token string">'cs_referrer_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'{}://{}{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>cs_referrer_parse<span class="token punctuation">.</span>scheme<span class="token punctuation">,</span> cs_referrer_parse<span class="token punctuation">.</span>netloc<span class="token punctuation">,</span> cs_referrer_parse<span class="token punctuation">.</span>path<span class="token punctuation">)</span> <span class="token keyword">if</span> cs_referrer_parse <span class="token keyword">else</span> <span class="token boolean">None</span>
  
  rec<span class="token punctuation">[</span><span class="token string">'d_du_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> d_du_url
  <span class="token keyword">for</span> k <span class="token keyword">in</span> d_du_query<span class="token punctuation">:</span>
    query<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> d_du_query<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">if</span> k <span class="token keyword">not</span> <span class="token keyword">in</span> query <span class="token keyword">else</span> query<span class="token punctuation">[</span>k<span class="token punctuation">]</span>

  <span class="token keyword">for</span> k <span class="token keyword">in</span> query<span class="token punctuation">:</span>
    rec<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> query<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">if</span> k <span class="token keyword">not</span> <span class="token keyword">in</span> rec <span class="token keyword">else</span> rec<span class="token punctuation">[</span>k<span class="token punctuation">]</span>

  out_rec <span class="token operator">=</span> <span class="token punctuation">{</span>ft<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>rec<span class="token punctuation">[</span>ft<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">if</span> ft<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> rec <span class="token keyword">else</span> <span class="token boolean">None</span> <span class="token keyword">for</span> ft <span class="token keyword">in</span> fields_types<span class="token punctuation">}</span>

  <span class="token keyword">return</span> <span class="token punctuation">[</span>out_rec<span class="token punctuation">[</span>ft<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> ft <span class="token keyword">in</span> fields_types<span class="token punctuation">]</span>

rdd3 <span class="token operator">=</span> rdd2<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>transform_1<span class="token punctuation">)</span>
schema <span class="token operator">=</span> sparko<span class="token punctuation">.</span>create_schema<span class="token punctuation">(</span>fields<span class="token operator">=</span><span class="token punctuation">[</span>f<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> fields_types<span class="token punctuation">]</span><span class="token punctuation">,</span> types<span class="token operator">=</span><span class="token punctuation">[</span>f<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> fields_types<span class="token punctuation">]</span><span class="token punctuation">)</span>
df3 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>rdd3<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="flatmap"><a href="#flatmap" aria-hidden="true" class="header-anchor">#</a> flatMap</h3> <div class="language-scala extra-class"><pre class="language-scala"><code>callData <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">&quot;User1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;User2&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&quot;User1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;User3&quot;</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&quot;User2&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;User1&quot;</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

calls <span class="token operator">=</span> callData<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>lambda record<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>record<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> record<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>record<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> record<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
print calls<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
# prints <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'User1'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User2'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User1'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User3'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User2'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User1'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

reduce <span class="token operator">=</span> calls<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>lambda a<span class="token punctuation">,</span> b<span class="token operator">:</span> a <span class="token operator">+</span> b<span class="token punctuation">)</span>
print reduce<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
# prints <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'User2'</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User3'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'User1'</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre></div><div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql</span><span class="token punctuation">.</span>_
<span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits</span><span class="token punctuation">.</span>_

<span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;K1&quot;</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;K2&quot;</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> yourDF <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>list<span class="token punctuation">)</span><span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;Key&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;Today&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;MTD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;QTD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;HTD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;YTD&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// yourDF.show()</span>
<span class="token comment">// +---+-----+---+---+---+---+</span>
<span class="token comment">// |Key|Today|MTD|QTD|HTD|YTD|</span>
<span class="token comment">// +---+-----+---+---+---+---+</span>
<span class="token comment">// | K1|   10| 20| 10| 20| 50|</span>
<span class="token comment">// | K2|   20| 30| 20| 10| 60|</span>
<span class="token comment">// +---+-----+---+---+---+---+</span>

<span class="token keyword">val</span> newDataFrame <span class="token operator">=</span> yourDF
  <span class="token punctuation">.</span>rdd
  <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> key <span class="token operator">=</span> row<span class="token punctuation">.</span>getString<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> todayAmt <span class="token operator">=</span> row<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> mtdAmt <span class="token operator">=</span> row<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> qtdAmt <span class="token operator">=</span> row<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> htdAmt <span class="token operator">=</span> row<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ytdAmt <span class="token operator">=</span> row<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>

    List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token string">&quot;today&quot;</span><span class="token punctuation">,</span> todayAmt<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token string">&quot;MTD&quot;</span><span class="token punctuation">,</span> mtdAmt<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token string">&quot;QTD&quot;</span><span class="token punctuation">,</span> qtdAmt<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token string">&quot;HTD&quot;</span><span class="token punctuation">,</span> htdAmt<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token string">&quot;YTD&quot;</span><span class="token punctuation">,</span> ytdAmt<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">}</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;Key&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;PRD&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;Amt&quot;</span> <span class="token punctuation">)</span>

<span class="token comment">// newDataFrame.show()</span>
<span class="token comment">// +---+-----+---+</span>
<span class="token comment">// |Key|  PRD|Amt|</span>
<span class="token comment">// +---+-----+---+</span>
<span class="token comment">// | K1|today| 10|</span>
<span class="token comment">// | K1|  MTD| 20|</span>
<span class="token comment">// | K1|  QTD| 10|</span>
<span class="token comment">// | K1|  HTD| 20|</span>
<span class="token comment">// | K1|  YTD| 50|</span>
<span class="token comment">// | K2|today| 20|</span>
<span class="token comment">// | K2|  MTD| 30|</span>
<span class="token comment">// | K2|  QTD| 20|</span>
<span class="token comment">// | K2|  HTD| 10|</span>
<span class="token comment">// | K2|  YTD| 60|</span>
<span class="token comment">// +---+-----+---+</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">transform_1</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">:</span>
  rec <span class="token operator">=</span> row<span class="token punctuation">.</span>asDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
  query <span class="token operator">=</span> parse_qs<span class="token punctuation">(</span>row<span class="token punctuation">.</span>cs_uri_query<span class="token punctuation">)</span> <span class="token keyword">if</span> row<span class="token punctuation">.</span>cs_uri_query <span class="token keyword">else</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
  query <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[\r\n\t]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> query<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> query<span class="token punctuation">}</span>
  cookies_keys <span class="token operator">=</span> parse_cookie<span class="token punctuation">(</span>row<span class="token punctuation">.</span>cs_cookie<span class="token punctuation">)</span>
  d_du_query <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

  <span class="token keyword">if</span> <span class="token string">'d_du'</span> <span class="token keyword">in</span> query<span class="token punctuation">:</span>
    d_data <span class="token operator">=</span> urlparse<span class="token punctuation">(</span>query<span class="token punctuation">[</span><span class="token string">'d_du'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    domain <span class="token operator">=</span> d_data<span class="token punctuation">.</span>netloc
    d_du_query <span class="token operator">=</span> parse_qs<span class="token punctuation">(</span>d_data<span class="token punctuation">.</span>query<span class="token punctuation">)</span>
    d_du_query <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[\r\n\t]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> d_du_query<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> d_du_query<span class="token punctuation">}</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    domain <span class="token operator">=</span> <span class="token boolean">None</span>
    
  
  out_rows <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> k <span class="token keyword">in</span> query<span class="token punctuation">:</span>
    row <span class="token operator">=</span> <span class="token punctuation">(</span>domain<span class="token punctuation">,</span> <span class="token string">'cs_uri_query'</span><span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token keyword">if</span> query<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
    out_rows<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">)</span>

  <span class="token keyword">for</span> k <span class="token keyword">in</span> d_du_query<span class="token punctuation">:</span>
    row <span class="token operator">=</span> <span class="token punctuation">(</span>domain<span class="token punctuation">,</span> <span class="token string">'d_du'</span><span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token keyword">if</span> d_du_query<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
    out_rows<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">)</span>

  <span class="token keyword">for</span> k <span class="token keyword">in</span> cookies_keys<span class="token punctuation">:</span>
    row <span class="token operator">=</span> <span class="token punctuation">(</span>domain<span class="token punctuation">,</span> <span class="token string">'cs_cookie'</span><span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token keyword">if</span> cookies_keys<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
    out_rows<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">)</span>

  <span class="token keyword">return</span> out_rows

rdd3 <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>transform_1<span class="token punctuation">)</span>
schema <span class="token operator">=</span> sparko<span class="token punctuation">.</span>create_schema<span class="token punctuation">(</span>fields<span class="token operator">=</span><span class="token punctuation">[</span>f<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> fields_types<span class="token punctuation">]</span><span class="token punctuation">,</span> types<span class="token operator">=</span><span class="token punctuation">[</span>f<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> fields_types<span class="token punctuation">]</span><span class="token punctuation">)</span>
df3 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>rdd3<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span>

</code></pre></div><h2 id="pivot"><a href="#pivot" aria-hidden="true" class="header-anchor">#</a> Pivot</h2> <div class="language-python extra-class"><pre class="language-python"><code>df <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">'select POL_QUOTE_STATUS_DESC,POL_STATUS_DESC, year(POL_EFF_DT) as POL_EFF_DT_YR from schema.tab'</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">'POL_QUOTE_STATUS_DESC'</span><span class="token punctuation">,</span> <span class="token string">'POL_EFF_DT_YR'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pivot<span class="token punctuation">(</span><span class="token string">'POL_STATUS_DESC'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span>
 sparko<span class="token punctuation">.</span>write_csv2<span class="token punctuation">(</span>df2<span class="token punctuation">,</span> <span class="token string">'/file.csv'</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="n-grams"><a href="#n-grams" aria-hidden="true" class="header-anchor">#</a> N-grams</h2> <div class="language-python extra-class"><pre class="language-python"><code>df1 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select connid, regexp_replace(mdibubble, '\\\\\\\\n', ' ') as mdibubble from schema.tab where mdibubble is not null limit 10000&quot;</span><span class="token punctuation">)</span>
df_tk <span class="token operator">=</span> sparko<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>df1<span class="token punctuation">,</span> <span class="token string">'mdibubble'</span><span class="token punctuation">,</span> <span class="token string">'mdibubble_tk'</span><span class="token punctuation">)</span>
df_tks <span class="token operator">=</span> sparko<span class="token punctuation">.</span>remove_stop_words<span class="token punctuation">(</span>df_tk<span class="token punctuation">,</span> <span class="token string">'mdibubble_tk'</span><span class="token punctuation">,</span> <span class="token string">'mdibubble_tks'</span><span class="token punctuation">)</span>
df_ng3 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>create_ngram<span class="token punctuation">(</span>df_tks<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'mdibubble_tks'</span><span class="token punctuation">,</span> <span class="token string">'mdibubble_ngram3'</span><span class="token punctuation">)</span>
df_ng3<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">'df_ng3'</span><span class="token punctuation">)</span>

df2 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">'select mdibubble_ngram3, size(mdibubble_ngram3) ng_tot from df_ng3'</span><span class="token punctuation">)</span>
<span class="token comment"># df2.show()</span>

df3 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
  select
    mdibubble_ngram,
    split(mdibubble_ngram, ' ') as mdibubble_ngram_arr,
    size(split(mdibubble_ngram, ' ')) as mdibubble_ngram_arr_size,
    size(mdibubble_ngram3) as ng_tot
  from df_ng3
  lateral view explode(mdibubble_ngram3) et1 AS mdibubble_ngram
&quot;&quot;&quot;</span><span class="token punctuation">)</span>
df3<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">'df3'</span><span class="token punctuation">)</span>
<span class="token comment"># df3.show()</span>

df4 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
  select
    mdibubble_ngram_arr,
    mdibubble_ngram_arr_size,
    count(1) cnt
  from df3
  group by mdibubble_ngram_arr, mdibubble_ngram_arr_size
  order by count(1) desc
&quot;&quot;&quot;</span><span class="token punctuation">)</span>
df4<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="histogram"><a href="#histogram" aria-hidden="true" class="header-anchor">#</a> Histogram</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>ml<span class="token punctuation">.</span>feature <span class="token keyword">import</span> QuantileDiscretizer

df <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">'select talk_time from schema.tab'</span><span class="token punctuation">)</span>

df<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>histogram<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>histogram<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">5000</span><span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">50000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

field_name <span class="token operator">=</span> <span class="token string">'talk_time'</span>
table <span class="token operator">=</span> <span class="token string">'schema.tab'</span>
numBuckets<span class="token operator">=</span><span class="token number">20</span>

df <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">'select cast({field} as double) as {field} from {table}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>field_name<span class="token punctuation">,</span> table<span class="token operator">=</span>table<span class="token punctuation">)</span><span class="token punctuation">)</span>

qds <span class="token operator">=</span> QuantileDiscretizer<span class="token punctuation">(</span>
  numBuckets<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
  inputCol<span class="token operator">=</span>field_name<span class="token punctuation">,</span>
  outputCol<span class="token operator">=</span><span class="token string">&quot;bucket&quot;</span><span class="token punctuation">,</span>
  relativeError<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
  handleInvalid<span class="token operator">=</span><span class="token string">&quot;error&quot;</span>
<span class="token punctuation">)</span>
bucketizer <span class="token operator">=</span> qds<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
df1 <span class="token operator">=</span> bucketizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>df<span class="token punctuation">)</span>

df1<span class="token punctuation">.</span>registerTempTable<span class="token punctuation">(</span><span class="token string">&quot;df1&quot;</span><span class="token punctuation">)</span>

df2 <span class="token operator">=</span> sparko<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''
with t1 as (
  select
    bucket, count(1) cnt,
    min({field}) min_val,
    max({field}) max_val,
    1 one
  from df1
  group by bucket
  order by bucket
)
, t2 as (
  select
    1 one,
    sum(cnt) tot_cnt
  from t1
)
select
  bucket, cnt,
  round(100 * cnt / tot_cnt, 1) prct,
  min_val, max_val
from t1
join t2 on t1.one = t2.one
'''</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>field<span class="token operator">=</span>field_name<span class="token punctuation">)</span><span class="token punctuation">)</span>

df2<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="fill-nulls-down"><a href="#fill-nulls-down" aria-hidden="true" class="header-anchor">#</a> Fill nulls down</h2> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- https://stackoverflow.com/questions/31144947/filling-null-value-from-last-not-null-value-in-hive</span>
<span class="token keyword">select</span>
  <span class="token keyword">coalesce</span><span class="token punctuation">(</span>field1<span class="token punctuation">,</span> last_value<span class="token punctuation">(</span>field1<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> field1 <span class="token keyword">order</span> <span class="token keyword">by</span> field1<span class="token punctuation">,</span> field2 <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">unbounded</span> <span class="token keyword">preceding</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> field1<span class="token punctuation">,</span>
  <span class="token keyword">coalesce</span><span class="token punctuation">(</span>field2<span class="token punctuation">,</span> last_value<span class="token punctuation">(</span>field2<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> field1 <span class="token keyword">order</span> <span class="token keyword">by</span> field1<span class="token punctuation">,</span> field2 <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">unbounded</span> <span class="token keyword">preceding</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> field2<span class="token punctuation">,</span>
  <span class="token keyword">coalesce</span><span class="token punctuation">(</span>pol_term_id<span class="token punctuation">,</span> last_value<span class="token punctuation">(</span>pol_term_id<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> field1 <span class="token keyword">order</span> <span class="token keyword">by</span> field1<span class="token punctuation">,</span> field2 <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">unbounded</span> <span class="token keyword">preceding</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> pol_term_id
<span class="token keyword">from</span> t1<span class="token punctuation">;</span>
</code></pre></div><h1 id="scala"><a href="#scala" aria-hidden="true" class="header-anchor">#</a> Scala</h1> <h2 id="packaging-and-submitting"><a href="#packaging-and-submitting" aria-hidden="true" class="header-anchor">#</a> Packaging and Submitting</h2> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">cd</span> /path/to/project_abc
sbt package
spark-submit --class <span class="token string">&quot;class.name.to.run&quot;</span> --master local<span class="token punctuation">[</span>2<span class="token punctuation">]</span> /path/to/project_abc/target/scala-2.11/project_abc_2.11-1.0.jar
</code></pre></div><h3 id="getting-all-class-names-in-jar"><a href="#getting-all-class-names-in-jar" aria-hidden="true" class="header-anchor">#</a> Getting all Class Names in JAR</h3> <div class="language-bash extra-class"><pre class="language-bash"><code>jar tvf build/libs/App1-standalone-0.1.jar <span class="token operator">|</span> <span class="token function">grep</span> class.prefix
</code></pre></div></div> <div class="page-edit"><!----> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/docs/database/sas.html" class="prev">
          SAS
        </a></span> <span class="next"><a href="/docs/database/mongodb.html">
          MongoDB
        </a>
        →
      </span></p></div> </div> <!----></div></div>
    <script src="/assets/js/app.ba1a83e9.js" defer></script><script src="/assets/js/16.0cf70ede.js" defer></script>
  </body>
</html>
